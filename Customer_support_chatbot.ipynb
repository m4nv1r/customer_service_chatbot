{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDXaGfKonN_f"
   },
   "source": [
    "# Customer Support Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZQhoEtqnN_g"
   },
   "source": [
    "We are going to use Deep Learning to train a customer support chatbot. We are going to use the Customer Support on Twitter dataset which can be found here:  https://www.kaggle.com/thoughtvector/customer-support-on-twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwLNwkJAnN_h"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x5uEIWG0nN_h",
    "outputId": "5785b269-541e-4bed-8670-f3561b6a0193"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nO8iIi6nN_m"
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GDTPkl_nN_m"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('twcs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "odGs3IN-nN_p",
    "outputId": "0c7f6aff-0052-4582-872f-6af2974caa15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mMi5XoponN_r",
    "outputId": "860f912a-b625-4bb8-c807-04c2c3186aec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2811774, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abxF0DtanN_2"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a new dataset where each row contains a customer's tweet and a company's response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First all the customer tweets need to be identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-os756TnN_2"
   },
   "outputs": [],
   "source": [
    "customer_tweets = data[pd.isnull(data.in_response_to_tweet_id) & data.inbound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "u-cDptJanN_5",
    "outputId": "6a6c2693-7047-4dd1-a8dd-771eb45b99d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 19:56:01 +0000 2017</td>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>115715</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:03:34 +0000 2017</td>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29</td>\n",
       "      <td>115716</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:01:35 +0000 2017</td>\n",
       "      <td>actually that's a broken link you sent me and ...</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31</td>\n",
       "      <td>115717</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:06:54 +0000 2017</td>\n",
       "      <td>Yo @Ask_Spectrum, your customer service reps a...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id author_id  inbound                      created_at  \\\n",
       "6          8    115712     True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "12        18    115713     True  Tue Oct 31 19:56:01 +0000 2017   \n",
       "14        20    115715     True  Tue Oct 31 22:03:34 +0000 2017   \n",
       "23        29    115716     True  Tue Oct 31 22:01:35 +0000 2017   \n",
       "25        31    115717     True  Tue Oct 31 22:06:54 +0000 2017   \n",
       "\n",
       "                                                 text response_tweet_id  \\\n",
       "6           @sprintcare is the worst customer service            9,6,10   \n",
       "12  @115714 y’all lie about your “great” connectio...                17   \n",
       "14  @115714 whenever I contact customer support, t...                19   \n",
       "23  actually that's a broken link you sent me and ...                28   \n",
       "25  Yo @Ask_Spectrum, your customer service reps a...                30   \n",
       "\n",
       "    in_response_to_tweet_id  \n",
       "6                       NaN  \n",
       "12                      NaN  \n",
       "14                      NaN  \n",
       "23                      NaN  \n",
       "25                      NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the desired dataset will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlH-FXlgnN_7"
   },
   "outputs": [],
   "source": [
    "customer_tweets_and_responses = pd.merge(customer_tweets, data, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "colab_type": "code",
    "id": "braugKK_nN_-",
    "outputId": "84db80f0-7028-4f5f-c08d-d335102f728f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id_x</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>inbound_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>response_tweet_id_x</th>\n",
       "      <th>in_response_to_tweet_id_x</th>\n",
       "      <th>tweet_id_y</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>inbound_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>response_tweet_id_y</th>\n",
       "      <th>in_response_to_tweet_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "      <td>5,7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:14 +0000 2017</td>\n",
       "      <td>@115712 I would love the chance to review the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:45:59 +0000 2017</td>\n",
       "      <td>@115712 Hello! We never like our customers to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 19:56:01 +0000 2017</td>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 19:59:13 +0000 2017</td>\n",
       "      <td>@115713 H there! We'd definitely like to work ...</td>\n",
       "      <td>16</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>115715</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:03:34 +0000 2017</td>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:10 +0000 2017</td>\n",
       "      <td>@115715 Please send me a private message so th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id_x author_id_x  inbound_x                    created_at_x  \\\n",
       "0           8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "1           8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "2           8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "3          18      115713       True  Tue Oct 31 19:56:01 +0000 2017   \n",
       "4          20      115715       True  Tue Oct 31 22:03:34 +0000 2017   \n",
       "\n",
       "                                              text_x response_tweet_id_x  \\\n",
       "0          @sprintcare is the worst customer service              9,6,10   \n",
       "1          @sprintcare is the worst customer service              9,6,10   \n",
       "2          @sprintcare is the worst customer service              9,6,10   \n",
       "3  @115714 y’all lie about your “great” connectio...                  17   \n",
       "4  @115714 whenever I contact customer support, t...                  19   \n",
       "\n",
       "   in_response_to_tweet_id_x  tweet_id_y author_id_y  inbound_y  \\\n",
       "0                        NaN           6  sprintcare      False   \n",
       "1                        NaN           9  sprintcare      False   \n",
       "2                        NaN          10  sprintcare      False   \n",
       "3                        NaN          17  sprintcare      False   \n",
       "4                        NaN          19  sprintcare      False   \n",
       "\n",
       "                     created_at_y  \\\n",
       "0  Tue Oct 31 21:46:24 +0000 2017   \n",
       "1  Tue Oct 31 21:46:14 +0000 2017   \n",
       "2  Tue Oct 31 21:45:59 +0000 2017   \n",
       "3  Tue Oct 31 19:59:13 +0000 2017   \n",
       "4  Tue Oct 31 22:10:10 +0000 2017   \n",
       "\n",
       "                                              text_y response_tweet_id_y  \\\n",
       "0  @115712 Can you please send us a private messa...                 5,7   \n",
       "1  @115712 I would love the chance to review the ...                 NaN   \n",
       "2  @115712 Hello! We never like our customers to ...                 NaN   \n",
       "3  @115713 H there! We'd definitely like to work ...                  16   \n",
       "4  @115715 Please send me a private message so th...                 NaN   \n",
       "\n",
       "   in_response_to_tweet_id_y  \n",
       "0                        8.0  \n",
       "1                        8.0  \n",
       "2                        8.0  \n",
       "3                       18.0  \n",
       "4                       20.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_tweets_and_responses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set may contain company tweets that are not responses to customer tweets (where inbound_y is True).\n",
    "These rows need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_42MrZAznOAC"
   },
   "outputs": [],
   "source": [
    "customer_tweets_and_responses = customer_tweets_and_responses[customer_tweets_and_responses.inbound_y == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "colab_type": "code",
    "id": "7CO4K9l0nOAE",
    "outputId": "cf42550d-2231-44f3-d448-32b3399cfac1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id_x</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>inbound_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>response_tweet_id_x</th>\n",
       "      <th>in_response_to_tweet_id_x</th>\n",
       "      <th>tweet_id_y</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>inbound_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>response_tweet_id_y</th>\n",
       "      <th>in_response_to_tweet_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "      <td>5,7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:14 +0000 2017</td>\n",
       "      <td>@115712 I would love the chance to review the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:45:59 +0000 2017</td>\n",
       "      <td>@115712 Hello! We never like our customers to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 19:56:01 +0000 2017</td>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 19:59:13 +0000 2017</td>\n",
       "      <td>@115713 H there! We'd definitely like to work ...</td>\n",
       "      <td>16</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>115715</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:03:34 +0000 2017</td>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:10 +0000 2017</td>\n",
       "      <td>@115715 Please send me a private message so th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id_x author_id_x  inbound_x                    created_at_x  \\\n",
       "0           8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "1           8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "2           8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "3          18      115713       True  Tue Oct 31 19:56:01 +0000 2017   \n",
       "4          20      115715       True  Tue Oct 31 22:03:34 +0000 2017   \n",
       "\n",
       "                                              text_x response_tweet_id_x  \\\n",
       "0          @sprintcare is the worst customer service              9,6,10   \n",
       "1          @sprintcare is the worst customer service              9,6,10   \n",
       "2          @sprintcare is the worst customer service              9,6,10   \n",
       "3  @115714 y’all lie about your “great” connectio...                  17   \n",
       "4  @115714 whenever I contact customer support, t...                  19   \n",
       "\n",
       "   in_response_to_tweet_id_x  tweet_id_y author_id_y  inbound_y  \\\n",
       "0                        NaN           6  sprintcare      False   \n",
       "1                        NaN           9  sprintcare      False   \n",
       "2                        NaN          10  sprintcare      False   \n",
       "3                        NaN          17  sprintcare      False   \n",
       "4                        NaN          19  sprintcare      False   \n",
       "\n",
       "                     created_at_y  \\\n",
       "0  Tue Oct 31 21:46:24 +0000 2017   \n",
       "1  Tue Oct 31 21:46:14 +0000 2017   \n",
       "2  Tue Oct 31 21:45:59 +0000 2017   \n",
       "3  Tue Oct 31 19:59:13 +0000 2017   \n",
       "4  Tue Oct 31 22:10:10 +0000 2017   \n",
       "\n",
       "                                              text_y response_tweet_id_y  \\\n",
       "0  @115712 Can you please send us a private messa...                 5,7   \n",
       "1  @115712 I would love the chance to review the ...                 NaN   \n",
       "2  @115712 Hello! We never like our customers to ...                 NaN   \n",
       "3  @115713 H there! We'd definitely like to work ...                  16   \n",
       "4  @115715 Please send me a private message so th...                 NaN   \n",
       "\n",
       "   in_response_to_tweet_id_y  \n",
       "0                        8.0  \n",
       "1                        8.0  \n",
       "2                        8.0  \n",
       "3                       18.0  \n",
       "4                       20.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_tweets_and_responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eIf0obPJnOAG",
    "outputId": "685cc720-0621-4451-896c-1f373cfab5fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794299, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_tweets_and_responses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to train our models on a fraction of the dataset since computers do not have enough RAM to train the models on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4vCycoBnOAJ"
   },
   "outputs": [],
   "source": [
    "customer_tweets_and_responses = customer_tweets_and_responses.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DcGNe5_rnOAL",
    "outputId": "2c61e8e2-e819-4516-bea1-f695af0c3aa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7943, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_tweets_and_responses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the customer screen names will be replaced with a generic placeholder (@_sn_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdSP8SkinOAN"
   },
   "outputs": [],
   "source": [
    "# Replace anonymized screen names with common token @_sn_\n",
    "\n",
    "sn_re = re.compile(r'@([^\\s:]+)')\n",
    "\n",
    "def sn_replace(txt):\n",
    "    handles = sn_re.findall(txt)\n",
    "    #print(handles)\n",
    "    for handle in handles:\n",
    "        if handle.isnumeric():\n",
    "            txt = txt.replace(handle, '_sn_')\n",
    "    return txt\n",
    "\n",
    "x_text = customer_tweets_and_responses.text_x.apply(lambda txt: sn_replace(txt))\n",
    "y_text = customer_tweets_and_responses.text_y.apply(lambda txt: sn_replace(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "zBVTknwMnOAQ",
    "outputId": "5f92f953-00e1-4aad-ff2a-dd9873d28dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "835199    @GWRHelp hi, Paddington to Swindon is delayed ...\n",
       "251227    Nothing like boarding your #HorizonAir @Alaska...\n",
       "507635    @AppleSupport iOS 11 is so bugged I need to re...\n",
       "833816    Sooo the global bank system for @_sn_ is down ...\n",
       "438132    Most Postal people would probably bawk at me f...\n",
       "Name: text_x, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "IVUgwPdnnOAS",
    "outputId": "a1594eba-e2ab-4333-ba6d-627998c9cb1e"
   },
   "outputs": [],
   "source": [
    "# 8192 - large enough for demonstration, larger values make network training slower\n",
    "MAX_VOCAB_SIZE = 2**13\n",
    "\n",
    "count_vec = CountVectorizer(tokenizer=TweetTokenizer().tokenize, max_features=MAX_VOCAB_SIZE - 3)\n",
    "count_vec.fit(x_text + y_text)\n",
    "analyzer = count_vec.build_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary will have three tokens. 'UNK' stands for unknown word. 'PAD' is used to pad short messages and 'START' is used to indicate the beginning of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIHxHTinnOAU"
   },
   "outputs": [],
   "source": [
    "UNK = 0\n",
    "PAD = 1\n",
    "START = 2 \n",
    "vocab = {k: v + 3 for k, v in count_vec.vocabulary_.items()}\n",
    "vocab['__unk__'] = UNK\n",
    "vocab['__pad__'] = PAD\n",
    "vocab['__start__'] = START\n",
    "# Used to turn seq2seq predictions into human readable strings\n",
    "reverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LO1cupYbnOAW",
    "outputId": "140d5653-58d7-474c-8f59-c1c8fdc6eb30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'word_idx' converts a sentence into its vector representation. 'word_idx_r' converts a vector representation of a sentence back into a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fngfWUoxnOAX"
   },
   "outputs": [],
   "source": [
    "MAX_MESSAGE_LEN = 30\n",
    "\n",
    "def word_idx(sentence):\n",
    "    full_length = [vocab.get(tok, UNK) for tok in analyzer(sentence)] + [PAD] * MAX_MESSAGE_LEN\n",
    "    return full_length[:MAX_MESSAGE_LEN]\n",
    "\n",
    "def word_idx_r(word_idxs):\n",
    "    return ' '.join(reverse_vocab[idx] for idx in word_idxs if idx != PAD).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tajBhTlTnOAa"
   },
   "outputs": [],
   "source": [
    "x = np.vstack(x_text.apply(word_idx).values)\n",
    "y = np.vstack(y_text.apply(word_idx).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mwDPBNlnOAc"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K2DOIRTxnOAh"
   },
   "outputs": [],
   "source": [
    "# Embedding size for an entire message\n",
    "EMBEDDING_SIZE = 100\n",
    "CONTEXT_SIZE = 100\n",
    "BATCH_SIZE = 4\n",
    "DROPOUT = 0.2\n",
    "# Learning rate\n",
    "lr=0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few seq2seq models will be trained and compared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WDakKutsnOAf"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Embedding, RepeatVector, concatenate, TimeDistributed\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuVJYM2pnOAk"
   },
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    shared_embedding = Embedding(\n",
    "        output_dim=EMBEDDING_SIZE,\n",
    "        input_dim=MAX_VOCAB_SIZE,\n",
    "        input_length=MAX_MESSAGE_LEN,\n",
    "        name='embedding',\n",
    "    )\n",
    "    \n",
    "    # ENCODER\n",
    "    \n",
    "    encoder_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN,),\n",
    "        dtype='int32',\n",
    "        name='encoder_input',\n",
    "    )\n",
    "    \n",
    "    embedded_input = shared_embedding(encoder_input)\n",
    "    \n",
    "    \n",
    "    encoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='encoder',\n",
    "        dropout=DROPOUT,\n",
    "    )\n",
    "    \n",
    "    context = RepeatVector(MAX_MESSAGE_LEN)(encoder_rnn(embedded_input))\n",
    "    \n",
    "    # DECODER\n",
    "    \n",
    "    last_word_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN, ),\n",
    "        dtype='int32',\n",
    "        name='last_word_input',\n",
    "    )\n",
    "    \n",
    "    embedded_last_word = shared_embedding(last_word_input)\n",
    "    \n",
    "    decoder_input = concatenate([embedded_last_word, context], axis=2)\n",
    "    \n",
    "    decoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='decoder',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    decoder_output = decoder_rnn(decoder_input)\n",
    "    \n",
    "    next_word_dense = TimeDistributed(\n",
    "        Dense(MAX_VOCAB_SIZE, activation='softmax'),\n",
    "        name='next_word_dense',\n",
    "    )(decoder_output)\n",
    "    \n",
    "    return Model(inputs=[encoder_input, last_word_input], outputs=[next_word_dense])\n",
    "\n",
    "s2s_model = nn_model()\n",
    "optimizer = Adam(lr=lr, clipvalue=5.0)\n",
    "s2s_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "last_word_input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      819200      encoder_input[0][0]              \n",
      "                                                                 last_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  (None, 100)          80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 100)      0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 200)      0           embedding[1][0]                  \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 30, 100)      120400      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "next_word_dense (TimeDistribute (None, 30, 8192)     827392      decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,847,392\n",
      "Trainable params: 1,847,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "s2s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojVceyXynOAo"
   },
   "outputs": [],
   "source": [
    "def add_start_token(y_array):\n",
    "    \"\"\" Add start token to vectors. \"\"\"\n",
    "    return np.hstack([\n",
    "        START * np.ones((len(y_array), 1)),\n",
    "        y_array[:, :-1],\n",
    "    ])\n",
    "\n",
    "def binarize_labels(labels):\n",
    "    \"\"\" Turns integer word indexes into sparse binary matrices for \n",
    "        the expected model output.\n",
    "    \"\"\"\n",
    "    return np.array([np_utils.to_categorical(row, num_classes=MAX_VOCAB_SIZE)\n",
    "                     for row in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "raXy272qnOAr"
   },
   "outputs": [],
   "source": [
    "def respond_to(model, text):\n",
    "    \"\"\" Generates a response to a customer's tweet \"\"\"\n",
    "    input_y = add_start_token(PAD * np.ones((1, MAX_MESSAGE_LEN)))\n",
    "    idxs = np.array(word_idx(text)).reshape((1, MAX_MESSAGE_LEN))\n",
    "    for position in range(MAX_MESSAGE_LEN - 1):\n",
    "        prediction = model.predict([idxs, input_y]).argmax(axis=2)[0]\n",
    "        input_y[:,position + 1] = prediction[position]\n",
    "    return word_idx_r(model.predict([idxs, input_y]).argmax(axis=2)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will be used to train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHGsY8_lnOAu"
   },
   "outputs": [],
   "source": [
    "def train_model(model, start_idx, end_idx):\n",
    "    \n",
    "    b_train_y = binarize_labels(y_train[start_idx:end_idx])\n",
    "    input_train_y = add_start_token(y_train[start_idx:end_idx])\n",
    "    \n",
    "    model.fit(\n",
    "        [X_train[start_idx:end_idx], input_train_y], \n",
    "        b_train_y,\n",
    "        epochs=1,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "    rand_idx = random.sample(list(range(len(X_test))), SUB_BATCH_SIZE)\n",
    "    \n",
    "    print('Test results:', model.evaluate(\n",
    "        [X_test[rand_idx], add_start_token(y_test[rand_idx])],\n",
    "        binarize_labels(y_test[rand_idx])\n",
    "    ))\n",
    "    \n",
    "    input_strings = [\n",
    "        \"@AmazonHelp I hadnt expected that such a big brand like amazon would have such a poor customer service.\",\n",
    "    ]\n",
    "    \n",
    "    for input_string in input_strings:\n",
    "        output_string = respond_to(model, input_string)\n",
    "        print(f'> \"{input_string}\"\\n< \"{output_string}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code will train the model for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xWUVGnznOA1"
   },
   "outputs": [],
   "source": [
    "SUB_BATCH_SIZE = 64\n",
    "for epoch in range(50):\n",
    "    print(f'Training in epoch {epoch}...')\n",
    "    for start_idx in range(0, len(X_train), SUB_BATCH_SIZE):\n",
    "        train_model(s2s_model, start_idx, start_idx + SUB_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be saved to a json file. The weights of the model will be saved in a hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t94qPTlqnOA3",
    "outputId": "d55babd0-bb92-406c-df40-e9764e88c586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = s2s_model.to_json()\n",
    "with open(\"model_50e.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "s2s_model.save_weights(\"model_50e.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a model with two LSTM layers (in addition to the encoder and decoder layers) will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    shared_embedding = Embedding(\n",
    "        output_dim=EMBEDDING_SIZE,\n",
    "        input_dim=MAX_VOCAB_SIZE,\n",
    "        input_length=MAX_MESSAGE_LEN,\n",
    "        name='embedding',\n",
    "    )\n",
    "    \n",
    "    # ENCODER\n",
    "    \n",
    "    encoder_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN,),\n",
    "        dtype='int32',\n",
    "        name='encoder_input',\n",
    "    )\n",
    "    \n",
    "    embedded_input = shared_embedding(encoder_input)\n",
    "    \n",
    "    \n",
    "    encoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='encoder',\n",
    "        dropout=DROPOUT,\n",
    "    )\n",
    "    \n",
    "    first_lstm = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='first_lstm',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    \n",
    "    context = RepeatVector(MAX_MESSAGE_LEN)(encoder_rnn(first_lstm(embedded_input)))\n",
    "    \n",
    "    # DECODER\n",
    "    \n",
    "    last_word_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN, ),\n",
    "        dtype='int32',\n",
    "        name='last_word_input',\n",
    "    )\n",
    "    \n",
    "    embedded_last_word = shared_embedding(last_word_input)\n",
    "    \n",
    "    decoder_input = concatenate([embedded_last_word, context], axis=2)\n",
    "    \n",
    "    decoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='decoder',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    last_lstm = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='last_lstm',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    decoder_output = last_lstm(decoder_rnn(decoder_input))\n",
    "    \n",
    "    next_word_dense = TimeDistributed(\n",
    "        Dense(int(MAX_VOCAB_SIZE/2), activation='relu'),\n",
    "        name='next_word_dense',\n",
    "    )(decoder_output)\n",
    "    \n",
    "    next_word = TimeDistributed(\n",
    "        Dense(MAX_VOCAB_SIZE, activation='softmax'),\n",
    "        name='next_word_softmax'\n",
    "    )(next_word_dense)\n",
    "    \n",
    "    return Model(inputs=[encoder_input, last_word_input], outputs=[next_word])\n",
    "\n",
    "s2s_model = nn_model()\n",
    "optimizer = Adam(lr=lr, clipvalue=5.0)\n",
    "s2s_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "colab_type": "code",
    "id": "pOkMe3mQnOAm",
    "outputId": "f64374b6-90dd-4920-bd72-5d1e06410893",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "last_word_input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      819200      encoder_input[0][0]              \n",
      "                                                                 last_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "first_lstm (LSTM)               (None, 30, 100)      80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  (None, 100)          80400       first_lstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 30, 100)      0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30, 200)      0           embedding[1][0]                  \n",
      "                                                                 repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 30, 100)      120400      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "last_lstm (LSTM)                (None, 30, 100)      80400       decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "next_word_dense (TimeDistribute (None, 30, 4096)     413696      last_lstm[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "next_word_softmax (TimeDistribu (None, 30, 8192)     33562624    next_word_dense[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 35,157,120\n",
      "Trainable params: 35,157,120\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "s2s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_BATCH_SIZE = 64\n",
    "for epoch in range(50):\n",
    "    print(f'Training in epoch {epoch}...')\n",
    "    for start_idx in range(0, len(X_train), SUB_BATCH_SIZE):\n",
    "        train_model(s2s_model, start_idx, start_idx + SUB_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = s2s_model.to_json()\n",
    "with open(\"model_2l_50e.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "s2s_model.save_weights(\"model_2l_50e.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a model with four LSTM layers (in addition to the encoder and decoder layers) will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    shared_embedding = Embedding(\n",
    "        output_dim=EMBEDDING_SIZE,\n",
    "        input_dim=MAX_VOCAB_SIZE,\n",
    "        input_length=MAX_MESSAGE_LEN,\n",
    "        name='embedding',\n",
    "    )\n",
    "    \n",
    "    # ENCODER\n",
    "    \n",
    "    encoder_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN,),\n",
    "        dtype='int32',\n",
    "        name='encoder_input',\n",
    "    )\n",
    "    \n",
    "    embedded_input = shared_embedding(encoder_input)\n",
    "    \n",
    "    \n",
    "    encoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='encoder',\n",
    "        dropout=DROPOUT,\n",
    "    )\n",
    "    \n",
    "    first_lstm = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='first_lstm',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    second_lstm = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='second_lstm',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    context = RepeatVector(MAX_MESSAGE_LEN)(encoder_rnn(second_lstm(first_lstm(embedded_input))))\n",
    "    \n",
    "    # DECODER\n",
    "    \n",
    "    last_word_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN, ),\n",
    "        dtype='int32',\n",
    "        name='last_word_input',\n",
    "    )\n",
    "    \n",
    "    embedded_last_word = shared_embedding(last_word_input)\n",
    "    \n",
    "    decoder_input = concatenate([embedded_last_word, context], axis=2)\n",
    "    \n",
    "    decoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='decoder',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    second_last_lstm = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='second_last_lstm',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    last_lstm = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='last_lstm',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    decoder_output = last_lstm(second_last_lstm(decoder_rnn(decoder_input)))\n",
    "    \n",
    "    next_word_dense = TimeDistributed(\n",
    "        Dense(int(MAX_VOCAB_SIZE/2), activation='relu'),\n",
    "        name='next_word_dense',\n",
    "    )(decoder_output)\n",
    "    \n",
    "    next_word = TimeDistributed(\n",
    "        Dense(MAX_VOCAB_SIZE, activation='softmax'),\n",
    "        name='next_word_softmax'\n",
    "    )(next_word_dense)\n",
    "    \n",
    "    return Model(inputs=[encoder_input, last_word_input], outputs=[next_word])\n",
    "\n",
    "s2s_model = nn_model()\n",
    "optimizer = Adam(lr=lr, clipvalue=5.0)\n",
    "s2s_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "last_word_input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      819200      encoder_input[0][0]              \n",
      "                                                                 last_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "first_lstm (LSTM)               (None, 30, 100)      80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "second_lstm (LSTM)              (None, 30, 100)      80400       first_lstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  (None, 100)          80400       second_lstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_4 (RepeatVector)  (None, 30, 100)      0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 30, 200)      0           embedding[1][0]                  \n",
      "                                                                 repeat_vector_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 30, 100)      120400      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "second_last_lstm (LSTM)         (None, 30, 100)      80400       decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "last_lstm (LSTM)                (None, 30, 100)      80400       second_last_lstm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "next_word_dense (TimeDistribute (None, 30, 4096)     413696      last_lstm[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "next_word_softmax (TimeDistribu (None, 30, 8192)     33562624    next_word_dense[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 35,317,920\n",
      "Trainable params: 35,317,920\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "s2s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_BATCH_SIZE = 64\n",
    "for epoch in range(50):\n",
    "    print(f'Training in epoch {epoch}...')\n",
    "    for start_idx in range(0, len(X_train), SUB_BATCH_SIZE):\n",
    "        train_model(s2s_model, start_idx, start_idx + SUB_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = s2s_model.to_json()\n",
    "with open(\"model_4l_50e.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "s2s_model.save_weights(\"model_4l_50e.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the models will be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o3CdjDP0tKBt"
   },
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kBXnoelDnOA6",
    "outputId": "cabcff51-1454-4d6a-a561-40b9338f011f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model_50e.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_50e.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "ZTh4YNFmswId",
    "outputId": "d91d3b19-8ce1-4079-d9f8-afc2d3a4e497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "last_word_input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      819200      encoder_input[0][0]              \n",
      "                                                                 last_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  (None, 100)          80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 100)      0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 200)      0           embedding[1][0]                  \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 30, 100)      120400      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "next_word_dense (TimeDistribute (None, 30, 8192)     827392      decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,847,392\n",
      "Trainable params: 1,847,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "nWt4kw2htDZY",
    "outputId": "91074092-2199-4c82-eab2-bcedfe1ef04d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589/1589 [==============================] - 3s 2ms/step\n",
      "Test results: 11.969458524801208\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "print('Test results:', loaded_model.evaluate(\n",
    "        [X_test, add_start_token(y_test)],\n",
    "        binarize_labels(y_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdKn89ygt7Rb"
   },
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zokzQOQOurHi",
    "outputId": "09fcd0b6-9e2a-4d61-8bcd-3a9cd4cb14c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model_2l_50e.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_2l_50e.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "colab_type": "code",
    "id": "7vGZPSB3u1yV",
    "outputId": "d7384547-3dbf-439e-cc5f-fc1eb36d0b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "last_word_input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      819200      encoder_input[0][0]              \n",
      "                                                                 last_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "first_lstm (LSTM)               (None, 30, 100)      80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  (None, 100)          80400       first_lstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 100)      0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 200)      0           embedding[1][0]                  \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 30, 100)      120400      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "last_lstm (LSTM)                (None, 30, 100)      80400       decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "next_word_dense (TimeDistribute (None, 30, 4096)     413696      last_lstm[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "next_word_softmax (TimeDistribu (None, 30, 8192)     33562624    next_word_dense[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 35,157,120\n",
      "Trainable params: 35,157,120\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "XbBLBmbvu8Vo",
    "outputId": "534f1324-06e2-4c9a-cf73-ac38950dd88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589/1589 [==============================] - 3s 2ms/step\n",
      "Test results: 4.170023515436018\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "print('Test results:', loaded_model.evaluate(\n",
    "        [X_test, add_start_token(y_test)],\n",
    "        binarize_labels(y_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVGkBEBTFcnr"
   },
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JH_aHkQgvF-5",
    "outputId": "dd730982-53fc-4874-fcd1-cb06b35f4a32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model_4l_50e.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_4l_50e.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "colab_type": "code",
    "id": "G_U5Sl1GFp5D",
    "outputId": "f70ed4e0-fa32-40b6-b1bc-8d1b6cd82e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "last_word_input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      819200      encoder_input[0][0]              \n",
      "                                                                 last_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "first_lstm (LSTM)               (None, 30, 100)      80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "second_lstm (LSTM)              (None, 30, 100)      80400       first_lstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  (None, 100)          80400       second_lstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 30, 100)      0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30, 200)      0           embedding[1][0]                  \n",
      "                                                                 repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 30, 100)      120400      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "second_last_lstm (LSTM)         (None, 30, 100)      80400       decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "last_lstm (LSTM)                (None, 30, 100)      80400       second_last_lstm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "next_word_dense (TimeDistribute (None, 30, 4096)     413696      last_lstm[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "next_word_softmax (TimeDistribu (None, 30, 8192)     33562624    next_word_dense[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 35,317,920\n",
      "Trainable params: 35,317,920\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "2h_JUVQSFy3X",
    "outputId": "69bc48a8-a731-4737-d809-dfad1629316e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589/1589 [==============================] - 5s 3ms/step\n",
      "Test results: 4.302756843512879\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "print('Test results:', loaded_model.evaluate(\n",
    "        [X_test, add_start_token(y_test)],\n",
    "        binarize_labels(y_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFnCfJqqF3Xj"
   },
   "source": [
    "The second model had the lowest loss which indicates that it is the best model. The fact that the third model had a higher loss than the second model suggests that adding additional layers to the second model might lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "https://www.kaggle.com/soaxelbrooke/twitter-basic-seq2seq"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Customer_support_chatbot_v6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "common-cpu.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
